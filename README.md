# ğŸ¬ Video Indexation & Object Detection Pipeline

This project performs a **complete video analysis pipeline** using Python.  
It extracts keyframes from a video, detects objects in each frame using **YOLOv5**,  
transcribes the audio track using **OpenAI Whisper**, and finally generates an **index file**
containing metadata, detected objects, and transcription results.

---

## ğŸ§  Features

- ğŸï¸ **Keyframe Extraction** â€” using OpenCV  
- ğŸ§ **Object Detection** â€” with YOLOv5 (Ultralytics)  
- ğŸ”Š **Audio Transcription** â€” via Whisper  
- ğŸ—‚ï¸ **Automatic Index Generation** â€” merging transcript and object data  
- ğŸ” **Search Functionality** â€” find any word with precise timestamps  

---

## ğŸ§© Project Structure

video-indexation/
â”‚
â”œâ”€â”€ indexation.py        # Main script (pipeline)
â”œâ”€â”€ README.md            # Project documentation
â”œâ”€â”€ requirements.txt     # List of dependencies
â”œâ”€â”€ .gitignore           # Git ignore rules
â”œâ”€â”€ video.mp4            # Input video (not uploaded to GitHub)
â”œâ”€â”€ frames/              # Extracted keyframes (auto-generated)
â”œâ”€â”€ video_index.txt      # Final index (auto-generated)
â””â”€â”€ ffmpeg/              # FFmpeg binaries (local use only)

---

## ğŸš€ How to Use

### ğŸ§° 1. Clone the Repository

git clone https://github.com/AymenKsouri/video-indexation.git
cd video-indexation

---

### ğŸ§± 2. Create & Activate a Virtual Environment

**Windows:**
python -m venv venv
venv\Scripts\activate

**Mac/Linux:**
python3 -m venv venv
source venv/bin/activate

---

### ğŸ“¦ 3. Install Dependencies

pip install -r requirements.txt

---

### ğŸ¥ 4. Add Your Video

Place your video in the same directory as `indexation.py`  
and rename it **video.mp4** (or modify the script to match your file name).

---

### â–¶ï¸ 5. Run the Script

python indexation.py

The script will:
- Extract keyframes into the `/frames` folder  
- Detect objects using YOLOv5  
- Transcribe audio with Whisper  
- Generate a `video_index.txt` file containing:
  - Video metadata  
  - Transcribed text  
  - Object detection results  

---

## ğŸ“„ Example Output

======= METADATA ===========
Frame Width: 1920
Frame Height: 1080
FPS: 30

===== TRANSCRIPTION =====
Hello everyone, welcome to the demo...

===== OBJECTS DETECTED =====
Frame: frame_0001.jpg, Object: person, Confidence: 0.88, Coordinates: (130.5, 220.1) - (450.3, 980.7)

---

## âš™ï¸ Requirements & Tools

| Tool | Purpose |
|------|----------|
| **Python 3.9+** | Base environment |
| **OpenCV** | Frame extraction |
| **MoviePy** | Video/audio processing |
| **Ultralytics YOLOv5** | Object detection |
| **OpenAI Whisper** | Speech-to-text transcription |
| **FFmpeg** | Required for MoviePy operations |

---

## âš ï¸ Notes

- ğŸ§± Donâ€™t upload heavy files like `.mp4`, `.wav`, or `.pt` to GitHub.  
- ğŸ§© Ensure **FFmpeg** is installed and added to your systemâ€™s PATH.  
- ğŸ“¦ The YOLOv5 model (`yolov5s.pt`) is automatically downloaded the first time it runs.

---

## ğŸ‘¤ Author

**Aymen Ksouri**  
ğŸ’» Computer Science Student | AI & Vision Enthusiast  
ğŸŒ [GitHub Profile](https://github.com/AymenKsouri)

---

â­ *If you find this project helpful, consider giving it a star on GitHub!*
